{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\wrigh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf = pd.read_csv('News Headlines + Sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Stock Data + Sentiment Final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>content</th>\n",
       "      <th>title sentiment</th>\n",
       "      <th>title sentiment score</th>\n",
       "      <th>content sentiment</th>\n",
       "      <th>content sentiment score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hillary Clinton’s point of no return</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Dan Merica</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Washington (CNN) As Democrats close to Hillary...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift’s year-end gift video brings all ...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Lisa Respers France</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Way to make us weep, Taylor Swift. As i...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is your tweet a threat? (Opinion)</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Danny Cevallos</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) The New York Police Department faced a ...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bono says he’s worried he may never play guita...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Lisa Respers France</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Bono has shared with fans that recovery...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.0</td>\n",
       "      <td>neutral</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donna Douglas, ’Beverly Hillbillies’ Elly May,...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Todd Leopold</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Donna Douglas, who played voluptuous to...</td>\n",
       "      <td>negative</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>positive</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title publication  \\\n",
       "0               Hillary Clinton’s point of no return         CNN   \n",
       "1  Taylor Swift’s year-end gift video brings all ...         CNN   \n",
       "2             When is your tweet a threat? (Opinion)         CNN   \n",
       "3  Bono says he’s worried he may never play guita...         CNN   \n",
       "4  Donna Douglas, ’Beverly Hillbillies’ Elly May,...         CNN   \n",
       "\n",
       "                author        date    year  month  \\\n",
       "0           Dan Merica  2015-01-01  2015.0    1.0   \n",
       "1  Lisa Respers France  2015-01-01  2015.0    1.0   \n",
       "2       Danny Cevallos  2015-01-02  2015.0    1.0   \n",
       "3  Lisa Respers France  2015-01-02  2015.0    1.0   \n",
       "4         Todd Leopold  2015-01-02  2015.0    1.0   \n",
       "\n",
       "                                             content title sentiment  \\\n",
       "0  Washington (CNN) As Democrats close to Hillary...         neutral   \n",
       "1   (CNN) Way to make us weep, Taylor Swift. As i...         neutral   \n",
       "2   (CNN) The New York Police Department faced a ...         neutral   \n",
       "3   (CNN) Bono has shared with fans that recovery...         neutral   \n",
       "4   (CNN) Donna Douglas, who played voluptuous to...        negative   \n",
       "\n",
       "   title sentiment score content sentiment  content sentiment score  \n",
       "0                    0.0          positive                    0.072  \n",
       "1                    0.0          positive                    0.118  \n",
       "2                    0.0          positive                    0.104  \n",
       "3                    0.0           neutral                    0.033  \n",
       "4                   -0.2          positive                    0.144  "
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>content sentiment score</th>\n",
       "      <th>title sentiment score</th>\n",
       "      <th>Exchange_Name</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>Dow Jones</td>\n",
       "      <td>17832.990234</td>\n",
       "      <td>17832.990234</td>\n",
       "      <td>17951.779297</td>\n",
       "      <td>17731.300781</td>\n",
       "      <td>17823.070313</td>\n",
       "      <td>76270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>10830.919922</td>\n",
       "      <td>10830.919922</td>\n",
       "      <td>10889.250000</td>\n",
       "      <td>10770.509766</td>\n",
       "      <td>10859.799805</td>\n",
       "      <td>2708700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>TSX/S&amp;P</td>\n",
       "      <td>14753.700195</td>\n",
       "      <td>14753.700195</td>\n",
       "      <td>14756.299805</td>\n",
       "      <td>14631.400391</td>\n",
       "      <td>14637.299805</td>\n",
       "      <td>132965800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>4726.810059</td>\n",
       "      <td>4726.810059</td>\n",
       "      <td>4777.009766</td>\n",
       "      <td>4698.109863</td>\n",
       "      <td>4760.240234</td>\n",
       "      <td>1435150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>S&amp;P</td>\n",
       "      <td>2058.199951</td>\n",
       "      <td>2058.199951</td>\n",
       "      <td>2072.360107</td>\n",
       "      <td>2046.040039</td>\n",
       "      <td>2058.899902</td>\n",
       "      <td>2708700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date  content sentiment score  title sentiment score Exchange_Name  \\\n",
       "0  2015-01-02                  0.07875               -0.01125     Dow Jones   \n",
       "1  2015-01-02                  0.07875               -0.01125          NYSE   \n",
       "2  2015-01-02                  0.07875               -0.01125       TSX/S&P   \n",
       "3  2015-01-02                  0.07875               -0.01125        NASDAQ   \n",
       "4  2015-01-02                  0.07875               -0.01125           S&P   \n",
       "\n",
       "      Adj Close         Close          High           Low          Open  \\\n",
       "0  17832.990234  17832.990234  17951.779297  17731.300781  17823.070313   \n",
       "1  10830.919922  10830.919922  10889.250000  10770.509766  10859.799805   \n",
       "2  14753.700195  14753.700195  14756.299805  14631.400391  14637.299805   \n",
       "3   4726.810059   4726.810059   4777.009766   4698.109863   4760.240234   \n",
       "4   2058.199951   2058.199951   2072.360107   2046.040039   2058.899902   \n",
       "\n",
       "       Volume  \n",
       "0    76270000  \n",
       "1  2708700000  \n",
       "2   132965800  \n",
       "3  1435150000  \n",
       "4  2708700000  "
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>content sentiment score</th>\n",
       "      <th>title sentiment score</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Close</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th>Exchange_Name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2015-01-02</th>\n",
       "      <th>Dow Jones</th>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>17832.990234</td>\n",
       "      <td>17832.990234</td>\n",
       "      <td>17951.779297</td>\n",
       "      <td>17731.300781</td>\n",
       "      <td>17823.070313</td>\n",
       "      <td>76270000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NYSE</th>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>10830.919922</td>\n",
       "      <td>10830.919922</td>\n",
       "      <td>10889.250000</td>\n",
       "      <td>10770.509766</td>\n",
       "      <td>10859.799805</td>\n",
       "      <td>2708700000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TSX/S&amp;P</th>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>14753.700195</td>\n",
       "      <td>14753.700195</td>\n",
       "      <td>14756.299805</td>\n",
       "      <td>14631.400391</td>\n",
       "      <td>14637.299805</td>\n",
       "      <td>132965800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NASDAQ</th>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>4726.810059</td>\n",
       "      <td>4726.810059</td>\n",
       "      <td>4777.009766</td>\n",
       "      <td>4698.109863</td>\n",
       "      <td>4760.240234</td>\n",
       "      <td>1435150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S&amp;P</th>\n",
       "      <td>0.07875</td>\n",
       "      <td>-0.01125</td>\n",
       "      <td>2058.199951</td>\n",
       "      <td>2058.199951</td>\n",
       "      <td>2072.360107</td>\n",
       "      <td>2046.040039</td>\n",
       "      <td>2058.899902</td>\n",
       "      <td>2708700000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          content sentiment score  title sentiment score  \\\n",
       "Date       Exchange_Name                                                   \n",
       "2015-01-02 Dow Jones                      0.07875               -0.01125   \n",
       "           NYSE                           0.07875               -0.01125   \n",
       "           TSX/S&P                        0.07875               -0.01125   \n",
       "           NASDAQ                         0.07875               -0.01125   \n",
       "           S&P                            0.07875               -0.01125   \n",
       "\n",
       "                             Adj Close         Close          High  \\\n",
       "Date       Exchange_Name                                             \n",
       "2015-01-02 Dow Jones      17832.990234  17832.990234  17951.779297   \n",
       "           NYSE           10830.919922  10830.919922  10889.250000   \n",
       "           TSX/S&P        14753.700195  14753.700195  14756.299805   \n",
       "           NASDAQ          4726.810059   4726.810059   4777.009766   \n",
       "           S&P             2058.199951   2058.199951   2072.360107   \n",
       "\n",
       "                                   Low          Open      Volume  \n",
       "Date       Exchange_Name                                          \n",
       "2015-01-02 Dow Jones      17731.300781  17823.070313    76270000  \n",
       "           NYSE           10770.509766  10859.799805  2708700000  \n",
       "           TSX/S&P        14631.400391  14637.299805   132965800  \n",
       "           NASDAQ          4698.109863   4760.240234  1435150000  \n",
       "           S&P             2046.040039   2058.899902  2708700000  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.set_index(['Date', 'Exchange_Name'], inplace = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['title_sentiment'] = [1 if score > 0.05 \n",
    "                             else -1 if score < -0.05\n",
    "                             else 0 \n",
    "                             for score in df['title sentiment score']]\n",
    "df['content_sentiment'] = [1 if score > 0.05 \n",
    "                             else -1 if score < -0.05\n",
    "                             else 0 \n",
    "                             for score in df['content sentiment score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removes dates where stock market wasn't open (i.e weekends, public holidays). Inner join occured, therefore content sentiment score can be indexed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "583"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Date.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(df[df['content sentiment score'] == 0].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "581"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Date.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Two values removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode sentiment labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "textdf.replace({'positive' : 1}, inplace = True)\n",
    "textdf.replace({'neutral' : 0}, inplace = True)\n",
    "textdf.replace({'negative' : -1}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>publication</th>\n",
       "      <th>author</th>\n",
       "      <th>date</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>content</th>\n",
       "      <th>title sentiment</th>\n",
       "      <th>title sentiment score</th>\n",
       "      <th>content sentiment</th>\n",
       "      <th>content sentiment score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Hillary Clinton’s point of no return</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Dan Merica</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Washington (CNN) As Democrats close to Hillary...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Taylor Swift’s year-end gift video brings all ...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Lisa Respers France</td>\n",
       "      <td>2015-01-01</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Way to make us weep, Taylor Swift. As i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>When is your tweet a threat? (Opinion)</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Danny Cevallos</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) The New York Police Department faced a ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bono says he’s worried he may never play guita...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Lisa Respers France</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Bono has shared with fans that recovery...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Donna Douglas, ’Beverly Hillbillies’ Elly May,...</td>\n",
       "      <td>CNN</td>\n",
       "      <td>Todd Leopold</td>\n",
       "      <td>2015-01-02</td>\n",
       "      <td>2015.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>(CNN) Donna Douglas, who played voluptuous to...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title publication  \\\n",
       "0               Hillary Clinton’s point of no return         CNN   \n",
       "1  Taylor Swift’s year-end gift video brings all ...         CNN   \n",
       "2             When is your tweet a threat? (Opinion)         CNN   \n",
       "3  Bono says he’s worried he may never play guita...         CNN   \n",
       "4  Donna Douglas, ’Beverly Hillbillies’ Elly May,...         CNN   \n",
       "\n",
       "                author        date    year  month  \\\n",
       "0           Dan Merica  2015-01-01  2015.0    1.0   \n",
       "1  Lisa Respers France  2015-01-01  2015.0    1.0   \n",
       "2       Danny Cevallos  2015-01-02  2015.0    1.0   \n",
       "3  Lisa Respers France  2015-01-02  2015.0    1.0   \n",
       "4         Todd Leopold  2015-01-02  2015.0    1.0   \n",
       "\n",
       "                                             content  title sentiment  \\\n",
       "0  Washington (CNN) As Democrats close to Hillary...                0   \n",
       "1   (CNN) Way to make us weep, Taylor Swift. As i...                0   \n",
       "2   (CNN) The New York Police Department faced a ...                0   \n",
       "3   (CNN) Bono has shared with fans that recovery...                0   \n",
       "4   (CNN) Donna Douglas, who played voluptuous to...               -1   \n",
       "\n",
       "   title sentiment score  content sentiment  content sentiment score  \n",
       "0                    0.0                  1                    0.072  \n",
       "1                    0.0                  1                    0.118  \n",
       "2                    0.0                  1                    0.104  \n",
       "3                    0.0                 -1                    0.033  \n",
       "4                   -0.2                  1                    0.144  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124584"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf.content.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    69564\n",
       " 1    34653\n",
       "-1    20367\n",
       "Name: title sentiment, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf['title sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    82165\n",
       " 0    36355\n",
       "-1     6064\n",
       "Name: content sentiment, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textdf['content sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    2716\n",
       " 0     134\n",
       "-1       5\n",
       "Name: content_sentiment, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0    2230\n",
       " 1     510\n",
       "-1     115\n",
       "Name: title_sentiment, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title_sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create training model for content text classification, min_df chosen as 2 to keep all articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_features = 1500, min_df=2, max_df=0.7, stop_words=stopwords.words('english'))\n",
    "content_text = cv.fit_transform(textdf['content']).toarray()\n",
    "sent_text = textdf['content sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124584, 1500)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124584,)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_text.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save data for csv in order to speed up process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('content_train.csv',content_text, delimiter =',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data back in "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_text = np.genfromtxt('content_train.csv', delimiter =',', skip_header = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Create TF-IDF Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf = TfidfTransformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_array = tfidf.fit_transform(content_text).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(124584, 1500)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Create Training Sets for textdf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_train, content_test, sent_train, sent_test = train_test_split(text_array, \n",
    "                                                                      sent_text, \n",
    "                                                                      test_size = 0.3, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_text_train = pd.DataFrame(content_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Run models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(content_train, sent_train)\n",
    "sent_pred = classifier.predict(content_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   68   834   980]\n",
      " [   86  3823  6946]\n",
      " [   14  2354 22271]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.40      0.04      0.07      1882\n",
      "           0       0.55      0.35      0.43     10855\n",
      "           1       0.74      0.90      0.81     24639\n",
      "\n",
      "    accuracy                           0.70     37376\n",
      "   macro avg       0.56      0.43      0.44     37376\n",
      "weighted avg       0.66      0.70      0.66     37376\n",
      "\n",
      "0.6999678938356164\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(sent_test,sent_pred))\n",
    "print(classification_report(sent_test,sent_pred))\n",
    "print(accuracy_score(sent_test, sent_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Multinomial Naive Bayes Model - 70% accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = GaussianNB()\n",
    "classifier.fit(content_train, sent_train)\n",
    "sent_pred = classifier.predict(content_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1181   409   292]\n",
      " [ 3171  4526  3158]\n",
      " [ 2656  5375 16608]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.17      0.63      0.27      1882\n",
      "           0       0.44      0.42      0.43     10855\n",
      "           1       0.83      0.67      0.74     24639\n",
      "\n",
      "    accuracy                           0.60     37376\n",
      "   macro avg       0.48      0.57      0.48     37376\n",
      "weighted avg       0.68      0.60      0.63     37376\n",
      "\n",
      "0.597040881849315\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(sent_test,sent_pred))\n",
    "print(classification_report(sent_test,sent_pred))\n",
    "print(accuracy_score(sent_test, sent_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Gaussian Naive Bayes Model - 60% Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "classifier = RandomForestClassifier(n_estimators= 100)\n",
    "classifier.fit(content_train, sent_train)\n",
    "sent_pred = classifier.predict(content_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   27   982   873]\n",
      " [   10  3159  7686]\n",
      " [    1  1169 23469]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.71      0.01      0.03      1882\n",
      "           0       0.59      0.29      0.39     10855\n",
      "           1       0.73      0.95      0.83     24639\n",
      "\n",
      "    accuracy                           0.71     37376\n",
      "   macro avg       0.68      0.42      0.42     37376\n",
      "weighted avg       0.69      0.71      0.66     37376\n",
      "\n",
      "0.713158176369863\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(sent_test,sent_pred))\n",
    "print(classification_report(sent_test,sent_pred))\n",
    "print(accuracy_score(sent_test, sent_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Random Forest Classifier - 71% accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'content_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f5a81b909ac9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0msent_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'content_train' is not defined"
     ]
    }
   ],
   "source": [
    "classifier = SVC()\n",
    "classifier.fit(content_train, sent_train)\n",
    "sent_pred = classifier.predict(content_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'confusion_matrix' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-8769421ca336>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msent_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msent_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msent_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msent_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'confusion_matrix' is not defined"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(sent_test,sent_pred))\n",
    "print(classification_report(sent_test,sent_pred))\n",
    "print(accuracy_score(sent_test, sent_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Support Vector Classification -  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
